{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_dist: [5.95804297e-34 5.95804297e-34 7.48469770e-35 5.90032239e-33\n",
      " 9.55045755e-36 6.06646474e-28 1.75055799e-26 3.68618294e-36\n",
      " 5.31092863e-25 1.32375316e-32] \n",
      "\n",
      "run_time: 0.080713\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyopencl as cl  # Import the OpenCL GPU computing API\n",
    "from pyopencl import clmath\n",
    "import pyopencl.array as pycl_array  # Import PyOpenCL Array \n",
    "\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('euc_dataset.csv', index_col = 'Unnamed: 0')\n",
    "df = df.dropna(subset=['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude'])\n",
    "df_ = df[:10000]\n",
    "\n",
    "def euc_distance_opencl(df):\n",
    "    context = cl.create_some_context()  # Initialize the Context\n",
    "    queue = cl.CommandQueue(context)  # Instantiate a Queue\n",
    "\n",
    "    # Create 4 random pyopencl arrays representing latitude x and longitude y for pickup point 1 and dropoff point 2\n",
    "    # x1 = pycl_array.to_device(queue, np.random.uniform(-90.0,90.0,1000000))\n",
    "    # x2 = pycl_array.to_device(queue, np.random.uniform(-90.0,90.0,1000000))\n",
    "    # y1 = pycl_array.to_device(queue, np.random.uniform(-180.0,180.0,1000000))\n",
    "    # y2 = pycl_array.to_device(queue, np.random.uniform(-180.0,180.0,1000000))\n",
    "\n",
    "    x1 = pycl_array.to_device(queue,np.array(df_['pickup_latitude']))\n",
    "    x2 = pycl_array.to_device(queue,np.array(df_['dropoff_latitude']))\n",
    "    y1 = pycl_array.to_device(queue,np.array(df_['pickup_longitude']))\n",
    "    y2 = pycl_array.to_device(queue,np.array(df_['dropoff_longitude']))\n",
    "\n",
    "    dist = pycl_array.empty_like(x1)  # Create an empty pyopencl distances array\n",
    "\n",
    "    program = cl.Program(context, \"\"\"\n",
    "    __kernel void cal_dist(__global const float *x1, __global const float *x2, __global const float *y1, \n",
    "    __global const float *y2, __global float *dist)\n",
    "    {\n",
    "      int i = get_global_id(0);\n",
    "      dist[i] = (x1[i]-x2[i])*(x1[i]-x2[i]) + (y1[i]-y2[i])*(y1[i]-y2[i]);\n",
    "    }\"\"\").build()  # Create the OpenCL program\n",
    "\n",
    "    # Enqueue the program for execution and store the result in c\n",
    "\n",
    "    program.cal_dist(queue, x1.shape, None, x1.data, x2.data, y1.data, y2.data, dist.data)  \n",
    "\n",
    "    sqrt_dist = cl.clmath.sqrt(dist, queue=None)\n",
    "\n",
    "    print(\"total_dist: {} \\n\".format(sqrt_dist[:10]))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 9.14 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "22.6 ms ± 23 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 euc_distance_opencl(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce\n",
    "To run the job, place the data on HDFS by issuing the command (replace the filename) from within the file directory:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hfs -put filename.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job should be launched by the following command:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hjs -file src/ -mapper src/mapper.sh -reducer src/reducer.sh -input filename.csv -output distance.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hjs command submits the job; the -file parameter indicates which files will be distributed to the worker nodes (i.e., the source code); the -mapper and -reducer parameters specify the paths to the mapper and reducer scripts; and the -input and -output paths specify the input file(s) and output file paths for the job. To retrieve the results of the computation, run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hfs -get distance.out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get all the partial outputs. To get the complete output as one file, run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hfs -getmerge distance.out distance_total.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import math \n",
    "\n",
    "for line in sys.stdin:\n",
    "        entry = line.strip().split(\",\")\n",
    "        \n",
    "        # Pickup Centroid Latitude, Pickup Centroid Longitude, Dropoff Centroid Latitude and Dropoff Centroid Longitude\n",
    "        pick_la, pick_lon, drop_la, drop_lon = entry[6],entry[7],entry[8],entry[9]\n",
    "        \n",
    "        # pick up community area\n",
    "        area = entry[5]\n",
    "        \n",
    "        # calculate euclidean distance for each trip\n",
    "        dist = math.sqrt((pick_la - drop_la)**2 + (pick_lon - drop_lon)**2)\n",
    "        \n",
    "        print('{}\\t{}'.format(area,dist))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_area = None\n",
    "current_dist = 0.0\n",
    "area = None\n",
    "dist = 0.0\n",
    "\n",
    "# number of trips in this area\n",
    "num_trips = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    area, dist = line.split('\\t', 1)\n",
    "            \n",
    "    # convert distance (currently a string) to int\n",
    "    try:\n",
    "        dist = float(dist)\n",
    "    except ValueError:\n",
    "        # dist was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    "\n",
    "    # Since Hadoop sorts map output by key (here: area) before it is passed to the reducer\n",
    "    if current_area == area:\n",
    "        current_dist += dist\n",
    "        num_trips += 1\n",
    "    else:\n",
    "        if current_area and i != 0:\n",
    "            # write result to STDOUT\n",
    "            print('{}\\t{}'.format(current_area, current_dist/num_trips))\n",
    "        current_area = area\n",
    "        current_dist = dist\n",
    "        num_trips = 0\n",
    "\n",
    "# Output the last area if needed\n",
    "if current_area == area and num_trips !=0:\n",
    "    print('{}\\t{}'.format(current_area, current_dist/num_trips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
